{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "58a437ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniconda/base/envs/hermes/lib/python3.13/site-packages/requests/__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniconda/base/envs/hermes/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e3d6aa1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at FacebookAI/roberta-large-mnli were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Device set to use mps:0\n"
     ]
    }
   ],
   "source": [
    "classifier = pipeline(\n",
    "    \"zero-shot-classification\",\n",
    "    model=\"FacebookAI/roberta-large-mnli\",\n",
    "    hypothesis_template=\"Under which topic would I see the following article in the news? The topics are: {}.\",\n",
    "    batch_size=64\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d789394c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# titles = [\"OpenAI releases GPT‑5\", \"Global markets rally on tech earnings\", \"Israel appoints new defense minister\", \"World Cup final ends in dramatic fashion\", \"New AI regulations proposed by EU\", \"OpenAI releases GPT‑5\", \"Global markets rally on tech earnings\", \"Israel appoints new defense minister\", \"World Cup final ends in dramatic fashion\", \"New AI regulations proposed by EU\", ] * 5\n",
    "\n",
    "# topics = [\"Technology\", \"Finance\", \"Sports\", \"Health\", \"Politics\"]\n",
    "\n",
    "# results = classifier(titles, candidate_labels=topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "23c20a59",
   "metadata": {},
   "outputs": [],
   "source": [
    "topics = [\"politics\", \"geopolitics\", \"economics\", \"entertainment\",\n",
    "          \"lifestyle\", \"sports\", \"science\", \"health\", \"business\", \"technology\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0c941b86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total articles: 51637\n"
     ]
    }
   ],
   "source": [
    "# connect to the database\n",
    "import pymongo\n",
    "from pymongo import MongoClient\n",
    "client = MongoClient(\"mongodb://localhost:27017/\")\n",
    "db = client[\"hermes\"]\n",
    "collection = db[\"articles\"]\n",
    "\n",
    "# loop though the articles and update the topic\n",
    "total = collection.count_documents({\"topic\": {\"$exists\": False}})\n",
    "print(f\"Total articles: {total}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37aa2f37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing articles in batches of 128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches: 100%|██████████| 404/404 [10:41:11<00:00, 95.23s/it]   \n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "# loop through the articles and update the topic in batches of 64 articles\n",
    "batch_size = 128\n",
    "print(f\"Processing articles in batches of {batch_size}\")\n",
    "for i in tqdm(range(0, total, batch_size), desc=\"Processing batches\"):\n",
    "    articles_cursor = collection.find({\"topic\": {\"$exists\": False}}).limit(batch_size)\n",
    "    articles = list(articles_cursor)\n",
    "    titles = [article[\"title\"] for article in articles]\n",
    "\n",
    "    results = classifier(titles, candidate_labels=topics)\n",
    "    for article, result in zip(articles, results):\n",
    "        collection.update_one({\"_id\": article[\"_id\"]}, {\"$set\": {\"topic\": result[\"labels\"][0]}})\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hermes",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
