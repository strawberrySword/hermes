{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nrms import NRMS\n",
    "\n",
    "model = NRMS(\n",
    "    vocab_size=50000\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clicked_token_ids=tensor([[[5959, 3717, 7365, 3245,    0,    0,    0,    0,    0,    0],\n",
      "         [3218, 8146, 3787, 3019, 7701,    0,    0,    0,    0,    0],\n",
      "         [3905,  347, 9549, 1592, 2368, 8427, 8634,    0,    0,    0],\n",
      "         [1660,  814, 3688,  990, 4592, 5597, 9580, 8579,    0,    0],\n",
      "         [2561, 5567, 1911, 1961,    0,    0,    0,    0,    0,    0]],\n",
      "\n",
      "        [[4245, 4673, 6280, 7812, 1732, 4769, 8557, 2882,    0,    0],\n",
      "         [2436,  120, 9091, 4894,    0,    0,    0,    0,    0,    0],\n",
      "         [7259, 4478, 7088, 1982, 8416, 4651, 7126, 3171, 5298,    0],\n",
      "         [4641, 9458,   79, 7506,  644, 3165, 3375, 2877, 4051,  402],\n",
      "         [4155, 9618, 9704,    0,    0,    0,    0,    0,    0,    0]]])\n",
      "clicked_token_ids.shape=torch.Size([2, 5, 10])\n",
      "clicked_token_mask=tensor([[[False, False, False, False,  True,  True,  True,  True,  True,  True],\n",
      "         [False, False, False, False, False,  True,  True,  True,  True,  True],\n",
      "         [False, False, False, False, False, False, False,  True,  True,  True],\n",
      "         [False, False, False, False, False, False, False, False,  True,  True],\n",
      "         [False, False, False, False,  True,  True,  True,  True,  True,  True]],\n",
      "\n",
      "        [[False, False, False, False, False, False, False, False,  True,  True],\n",
      "         [False, False, False, False,  True,  True,  True,  True,  True,  True],\n",
      "         [False, False, False, False, False, False, False, False, False,  True],\n",
      "         [False, False, False, False, False, False, False, False, False, False],\n",
      "         [False, False, False,  True,  True,  True,  True,  True,  True,  True]]])\n",
      "clicked_token_mask.shape=torch.Size([2, 5, 10])\n",
      "all_doc_token_ids=tensor([[6782, 2986, 8407, 8669, 8080, 7151, 9425,    0,    0,    0],\n",
      "        [6759, 3941, 9119, 9959, 5023,    0,    0,    0,    0,    0],\n",
      "        [9564, 5696, 4713, 2702, 4618,    0,    0,    0,    0,    0],\n",
      "        [8181, 2099, 2539, 8907,  334,    0,    0,    0,    0,    0],\n",
      "        [  32, 1042, 4319,  440, 9211, 2542,   26,    0,    0,    0],\n",
      "        [ 122, 1585, 3786, 7079,   33, 4678, 8242, 1014,    0,    0],\n",
      "        [2641, 9083, 8098, 3245, 6888,    0,    0,    0,    0,    0]])\n",
      "all_doc_token_ids.shape=torch.Size([7, 10])\n",
      "all_doc_token_mask=tensor([[False, False, False, False, False, False, False,  True,  True,  True],\n",
      "        [False, False, False, False, False,  True,  True,  True,  True,  True],\n",
      "        [False, False, False, False, False,  True,  True,  True,  True,  True],\n",
      "        [False, False, False, False, False,  True,  True,  True,  True,  True],\n",
      "        [False, False, False, False, False, False, False,  True,  True,  True],\n",
      "        [False, False, False, False, False, False, False, False,  True,  True],\n",
      "        [False, False, False, False, False,  True,  True,  True,  True,  True]])\n",
      "all_doc_token_mask.shape=torch.Size([7, 10])\n",
      "scores.shape=torch.Size([2, 7])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0., 0., 1., 0.],\n",
       "        [0., 0., 0., 0., 0., 1., 0.]], grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Settings\n",
    "B = 2       # batch size (users)\n",
    "N = 5       # max clicked articles per user\n",
    "D = 7       # number of total candidate/news documents\n",
    "L = 10      # max token length per article\n",
    "vocab_size = 10000  # vocabulary size\n",
    "\n",
    "PAD_TOKEN_ID = 0\n",
    "\n",
    "def generate_padded_articles(batch_size, num_articles, max_len, vocab_size, pad_token_id=0):\n",
    "    \"\"\"Generate a batch of padded articles and corresponding masks.\"\"\"\n",
    "    token_ids = torch.full((batch_size, num_articles, max_len), pad_token_id, dtype=torch.long)\n",
    "    token_mask = torch.ones((batch_size, num_articles, max_len), dtype=torch.bool)\n",
    "\n",
    "    for b in range(batch_size):\n",
    "        for n in range(num_articles):\n",
    "            real_len = torch.randint(3, max_len + 1, (1,)).item()\n",
    "            tokens = torch.randint(1, vocab_size, (real_len,))\n",
    "            token_ids[b, n, :real_len] = tokens\n",
    "            token_mask[b, n, :real_len] = False  # False means \"not masked\" (valid token)\n",
    "\n",
    "    return token_ids, token_mask\n",
    "\n",
    "def generate_padded_docs(num_docs, max_len, vocab_size, pad_token_id=0):\n",
    "    \"\"\"Generate a list of padded news documents and masks.\"\"\"\n",
    "    token_ids = torch.full((num_docs, max_len), pad_token_id, dtype=torch.long)\n",
    "    token_mask = torch.ones((num_docs, max_len), dtype=torch.bool)\n",
    "\n",
    "    for d in range(num_docs):\n",
    "        real_len = torch.randint(5, max_len + 1, (1,)).item()\n",
    "        tokens = torch.randint(1, vocab_size, (real_len,))\n",
    "        token_ids[d, :real_len] = tokens\n",
    "        token_mask[d, :real_len] = False\n",
    "\n",
    "    return token_ids, token_mask\n",
    "\n",
    "\n",
    "# Generate clicked history (B, N, L) and mask (B, N, L)\n",
    "clicked_token_ids, clicked_token_mask = generate_padded_articles(B, N, L, vocab_size, PAD_TOKEN_ID)\n",
    "\n",
    "# Generate all documents (D, L) and mask (D, L)\n",
    "all_doc_token_ids, all_doc_token_mask = generate_padded_docs(D, L, vocab_size, PAD_TOKEN_ID)\n",
    "\n",
    "# Model init & forward\n",
    "model = NRMS(vocab_size=vocab_size)\n",
    "scores = model(\n",
    "    clicked_token_ids=clicked_token_ids,\n",
    "    clicked_token_mask=clicked_token_mask,\n",
    "    all_doc_token_ids=all_doc_token_ids,\n",
    "    all_doc_token_mask=all_doc_token_mask,\n",
    ")\n",
    "\n",
    "print(f'{clicked_token_ids=}')\n",
    "print(f'{clicked_token_ids.shape=}')\n",
    "print(f'{clicked_token_mask=}')\n",
    "print(f'{clicked_token_mask.shape=}')\n",
    "print(f'{all_doc_token_ids=}')\n",
    "print(f'{all_doc_token_ids.shape=}')\n",
    "print(f'{all_doc_token_mask=}')\n",
    "print(f'{all_doc_token_mask.shape=}')\n",
    "print(f'{scores.shape=}')\n",
    "scores"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "recSys_kernel",
   "language": "python",
   "name": "recsys"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
