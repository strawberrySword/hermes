{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7ad96f8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup\n",
    "import os\n",
    "import wandb\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from nrms import NRMS\n",
    "from typing import List, Dict\n",
    "from torch.optim.adamw import AdamW\n",
    "from tqdm import tqdm\n",
    "import math\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import BertTokenizerFast, get_linear_schedule_with_warmup\n",
    "from data import load_and_tokenize_news, load_behaviors, MindDataset, mind_collate_fn\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0b82e695",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model: torch.nn.Module, \n",
    "                   dataloader: DataLoader, \n",
    "                   device: torch.device):\n",
    "    \"\"\"\n",
    "    Evaluates a news recommender model on a set of metrics:\n",
    "      - AUC (averaged per‐impression)\n",
    "      - MRR (Mean Reciprocal Rank)\n",
    "      - nDCG@5\n",
    "      - nDCG@10\n",
    "\n",
    "    Assumptions:\n",
    "      * Each batch from dataloader returns:\n",
    "          clicked_ids:   torch.LongTensor of shape (B, L_click)\n",
    "          clicked_mask:  torch.BoolTensor of  shape (B, L_click)\n",
    "          cand_ids:      torch.LongTensor of shape (B, K, L_cand)\n",
    "          cand_mask:     torch.BoolTensor of  shape (B, K, L_cand)\n",
    "          labels:        torch.LongTensor of shape (B,)\n",
    "            where labels[b] ∈ {0, …, K-1} is the index (in the candidate list)\n",
    "            of the single “clicked” article for instance b.\n",
    "      * The model’s forward pass is called as:\n",
    "            scores: torch.Tensor = model(clicked_ids, ~clicked_mask, \n",
    "                                         cand_ids, cand_mask)\n",
    "        and returns a FloatTensor of shape (B, K), where K is the number of candidates.\n",
    "\n",
    "    Returns:\n",
    "      A dict containing the four metrics:\n",
    "        {\n",
    "          \"AUC\": float,\n",
    "          \"MRR\": float,\n",
    "          \"nDCG@5\": float,\n",
    "          \"nDCG@10\": float\n",
    "        }\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "\n",
    "    total_auc = 0.0\n",
    "    total_mrr = 0.0\n",
    "    total_ndcg_5 = 0.0\n",
    "    total_ndcg_10 = 0.0\n",
    "    total_instances = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(dataloader):\n",
    "            # Unpack\n",
    "            clicked_ids, clicked_mask, cand_ids, cand_mask, labels = batch\n",
    "            # Move to device\n",
    "            clicked_ids  = clicked_ids.to(device)    # (B, L_click)\n",
    "            clicked_mask = clicked_mask.to(device)   # (B, L_click)\n",
    "            cand_ids     = cand_ids.to(device)       # (B, K, L_cand)\n",
    "            cand_mask    = cand_mask.to(device)      # (B, K, L_cand)\n",
    "            labels       = labels.to(device)         # (B,)\n",
    "\n",
    "            # Forward pass → scores of shape (B, K)\n",
    "            scores: torch.Tensor = model(\n",
    "                clicked_ids, \n",
    "                ~clicked_mask,   # note: model expects the bitwise inverse of clicked_mask\n",
    "                cand_ids, \n",
    "                cand_mask\n",
    "            )  # scores[b, j] is the predicted score/logit for candidate j of instance b\n",
    "\n",
    "            B, K = scores.shape\n",
    "            total_instances += B\n",
    "\n",
    "            # Convert to CPU+numpy for metric computations\n",
    "            scores_cpu = scores.cpu().numpy()      # shape (B, K)\n",
    "            labels_cpu = labels.cpu().numpy()      # shape (B,)\n",
    "\n",
    "            for b in range(B):\n",
    "                y_true = [0] * K\n",
    "                true_index = int(labels_cpu[b])\n",
    "                y_true[true_index] = 1\n",
    "\n",
    "                y_score = scores_cpu[b]  # length-K array of floats\n",
    "\n",
    "                # ----- AUC (per‐impression) -----\n",
    "                # If there is exactly one positive and K-1 negatives, roc_auc_score still works.\n",
    "                try:\n",
    "                    auc_b = roc_auc_score(y_true, y_score)\n",
    "                except ValueError:\n",
    "                    # In the rare case all y_true are the same label (shouldn't happen if exactly one click),\n",
    "                    # roc_auc_score will throw a ValueError. Fallback to 0.5.\n",
    "                    auc_b = 0.5\n",
    "                total_auc += auc_b\n",
    "\n",
    "                # ----- MRR (Mean Reciprocal Rank) -----\n",
    "                # Compute the rank (1-based) of the true_index in the sorted scores (descending)\n",
    "                # We can do this by counting how many scores are strictly greater than the score at true_index.\n",
    "                target_score = y_score[true_index]\n",
    "                # Rank is 1 + #items whose score > target_score\n",
    "                rank = 1 + int((y_score > target_score).sum())\n",
    "                # If multiple candidates have exactly the same score as the target, this effectively assigns\n",
    "                # the clicked item the worst possible rank among its ties. In practice, ties are rare.\n",
    "                rr = 1.0 / rank\n",
    "                total_mrr += rr\n",
    "\n",
    "                # ----- nDCG@5 and nDCG@10 -----\n",
    "                # The DCG formula for a single clicked item at position 'rank':\n",
    "                #   DCG@k = 1 / log2(rank + 1)   if rank <= k\n",
    "                #          = 0                   if rank > k\n",
    "                #\n",
    "                # Since there is exactly one positive, IDCG@k = 1.0 (clicked item at rank=1).\n",
    "                # Hence nDCG@k = DCG@k / IDCG@k = DCG@k.\n",
    "\n",
    "                # Precompute discount for this rank:\n",
    "                discount = 1.0 / math.log2(rank + 1)\n",
    "\n",
    "                # nDCG@5:\n",
    "                if rank <= 5:\n",
    "                    ndcg5_b = discount\n",
    "                else:\n",
    "                    ndcg5_b = 0.0\n",
    "                total_ndcg_5 += ndcg5_b\n",
    "\n",
    "                # nDCG@10:\n",
    "                if rank <= 10:\n",
    "                    ndcg10_b = discount\n",
    "                else:\n",
    "                    ndcg10_b = 0.0\n",
    "                total_ndcg_10 += ndcg10_b\n",
    "\n",
    "    # Compute averages\n",
    "    avg_auc    = total_auc / total_instances\n",
    "    avg_mrr    = total_mrr / total_instances\n",
    "    avg_ndcg_5 = total_ndcg_5 / total_instances\n",
    "    avg_ndcg_10= total_ndcg_10 / total_instances\n",
    "\n",
    "    return {\n",
    "        \"AUC\": avg_auc,\n",
    "        \"MRR\": avg_mrr,\n",
    "        \"nDCG@5\": avg_ndcg_5,\n",
    "        \"nDCG@10\": avg_ndcg_10\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1740cf9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_DATA_DIR = './data/MIND_'\n",
    "\n",
    "\n",
    "MAX_TITLE_LEN = 100   # each headline → exactly MAX_TITLE_LEN tokens (truncated/padded)\n",
    "MAX_HISTORY  = 50     # each user’s clicked history → exactly MAX_HISTORY articles\n",
    "BACTH_SIZE = 20\n",
    "\n",
    "\n",
    "tokenizer = BertTokenizerFast.from_pretrained('bert-base-uncased')\n",
    "PAD_ID = tokenizer.pad_token_id\n",
    "\n",
    "train_news_dict = load_and_tokenize_news(BASE_DATA_DIR+'train/news.tsv', tokenizer, MAX_TITLE_LEN)\n",
    "train_samples   = load_behaviors(BASE_DATA_DIR+'train/behaviors.tsv', train_news_dict, MAX_HISTORY)\n",
    "\n",
    "val_news_dict = load_and_tokenize_news(BASE_DATA_DIR+'val/news.tsv', tokenizer, MAX_TITLE_LEN)\n",
    "val_samples   = load_behaviors(BASE_DATA_DIR+'val/behaviors.tsv', val_news_dict, MAX_HISTORY)\n",
    "\n",
    "\n",
    "train_dataset = MindDataset(train_samples)\n",
    "val_dataset = MindDataset(val_samples)\n",
    "\n",
    "train_dl = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=BACTH_SIZE,\n",
    "    shuffle=True,\n",
    "    collate_fn=mind_collate_fn\n",
    ")\n",
    "\n",
    "valid_dl = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=BACTH_SIZE,\n",
    "    shuffle=True,\n",
    "    collate_fn=mind_collate_fn\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1966825c",
   "metadata": {},
   "source": [
    "# Load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "342b15b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Danik\\AppData\\Local\\Temp\\ipykernel_18680\\2728825207.py:25: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(CHECK_PATH, map_location=\"cpu\"))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nrms import NRMS\n",
    "\n",
    "CHECK_PATH = './checkpoints/checkpoint_epoch5.pt'\n",
    "\n",
    "# Constants — make sure these match your training settings\n",
    "MAX_HISTORY = 50\n",
    "MAX_TITLE_LEN = 100\n",
    "PAD_ID = 0  # [PAD] token for BERT\n",
    "\n",
    "# This has to be the same as the trained model\n",
    "model = NRMS(\n",
    "    vocab_size=tokenizer.vocab_size,\n",
    "    d_embed_word = 128,\n",
    "    d_embed_news = 256,\n",
    "    n_heads_news = 8,\n",
    "    n_heads_user = 8,\n",
    "    d_mlp_news = 512,\n",
    "    d_mlp_user = 512,\n",
    "    news_layers = 1,\n",
    "    user_layers = 1,\n",
    "    dropout = 0.1,\n",
    "    pad_max_len = MAX_TITLE_LEN,\n",
    ")\n",
    "\n",
    "model.load_state_dict(torch.load(CHECK_PATH, map_location=\"cpu\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "985fe086",
   "metadata": {},
   "source": [
    "# Eval on train (sanity check really)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2b1015b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/7849 [00:00<?, ?it/s]c:\\Users\\Danik\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\transformer.py:720: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:555.)\n",
      "  return torch._transformer_encoder_layer_fwd(\n",
      "c:\\Users\\Danik\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\transformer.py:409: UserWarning: The PyTorch API of nested tensors is in prototype stage and will change in the near future. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\NestedTensorImpl.cpp:180.)\n",
      "  output = torch._nested_tensor_from_mask(output, src_key_padding_mask.logical_not(), mask_check=False)\n",
      "100%|██████████| 7849/7849 [20:51<00:00,  6.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- Evaluation Metrics ----\n",
      "AUC = 0.9091\n",
      "MRR = 0.3410\n",
      "nDCG@5 = 0.3510\n",
      "nDCG@10 = 0.4041\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "metrics = evaluate_model(model, train_dl, torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"))\n",
    "print(\"---- Evaluation Metrics ----\")\n",
    "for metric_name, value in metrics.items():\n",
    "    print(f\"{metric_name} = {value:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ec4a0aa",
   "metadata": {},
   "source": [
    "# Eval on val set\n",
    "(should maybe eval on test set, take unseen subset of big MIND)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d024b486",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/3658 [00:00<?, ?it/s]c:\\Users\\Danik\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\transformer.py:720: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:555.)\n",
      "  return torch._transformer_encoder_layer_fwd(\n",
      "c:\\Users\\Danik\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\transformer.py:409: UserWarning: The PyTorch API of nested tensors is in prototype stage and will change in the near future. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\NestedTensorImpl.cpp:180.)\n",
      "  output = torch._nested_tensor_from_mask(output, src_key_padding_mask.logical_not(), mask_check=False)\n",
      "100%|██████████| 3658/3658 [10:14<00:00,  5.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- Evaluation Metrics ----\n",
      "AUC = 0.8892\n",
      "MRR = 0.2609\n",
      "nDCG@5 = 0.2722\n",
      "nDCG@10 = 0.3270\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "val_metrics = evaluate_model(model, valid_dl, torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"))\n",
    "print(\"---- Evaluation Metrics ----\")\n",
    "for metric_name, value in val_metrics.items():\n",
    "    print(f\"{metric_name} = {value:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a38683db",
   "metadata": {},
   "source": [
    "# Results & Baselines\n",
    "\n",
    "(All metrics - higher is better)\n",
    "\n",
    "\n",
    "| Model | AUC | MRR | nDCG@5 | nDCG@10 |\n",
    "| - | - | - | - | - |\n",
    "| Epoch2 | 0.8893 | 0.2632 | 0.2728 | 0.3290 |\n",
    "| Epoch5 | 0.8892 | 0.2609 | 0.2722 | 0.3270 |\n",
    "| NRMS paper (on large MIND) | 0.6275 | 0.2985 | 0.3217 | 0.4139 |\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
